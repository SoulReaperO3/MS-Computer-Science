{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================Started===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-5631918e0c3d>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  insulinMealDates['BWZ Carb Input (grams)'][ind] = (int)(insulinMealDates['BWZ Carb Input (grams)'][ind]/(minV + 20))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9927162575642885\n",
      "=====================Done===========================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.fftpack\n",
    "from sklearn.decomposition import PCA\n",
    "from math import log2\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "\n",
    "print(\"=====================Started===========================\")\n",
    "#load Insulin and CGM Data\n",
    "insulinDf = pd.read_csv('InsulinData.csv', parse_dates=[['Date','Time']],low_memory=False).iloc[::-1]\n",
    "cgmDf = pd.read_csv('CGMData.csv', parse_dates=[['Date','Time']],low_memory=False).iloc[::-1]\n",
    "\n",
    "insulinDFColY = insulinDf[insulinDf['BWZ Carb Input (grams)'].notnull() & insulinDf['BWZ Carb Input (grams)'] != 0]\n",
    "insulinMealDates = pd.DataFrame(insulinDFColY[['Date_Time','BWZ Carb Input (grams)']])\n",
    "\n",
    "insulinMealDates['Diff'] = insulinMealDates.iloc[:,0].diff(-1).dt.total_seconds().div(3600)\n",
    "insulinMealDates = insulinMealDates.loc[insulinMealDates['Diff'] <= -2]\n",
    "insulinMealDates.drop(insulinMealDates.head(1).index,inplace=True)\n",
    "insulinMealDates.drop(insulinMealDates.tail(2).index,inplace=True)\n",
    "\n",
    "binLen = 20\n",
    "minV = insulinMealDates['BWZ Carb Input (grams)'].min()\n",
    "maxV = insulinMealDates['BWZ Carb Input (grams)'].max()\n",
    "\n",
    "nBins = (int)((maxV - minV)/20)\n",
    "\n",
    "for ind in insulinMealDates.index:\n",
    "    insulinMealDates['BWZ Carb Input (grams)'][ind] = (int)(insulinMealDates['BWZ Carb Input (grams)'][ind]/(minV + 20))\n",
    "#     23,43,63,83,103,123,\n",
    "\n",
    "mealDatesList = []\n",
    "for ind in insulinMealDates.index: \n",
    "    l = []\n",
    "    l.append((cgmDf.loc[cgmDf['Date_Time'] >= insulinMealDates['Date_Time'][ind]])['Date_Time'].iloc[0])\n",
    "    l.append(insulinMealDates['BWZ Carb Input (grams)'][ind])\n",
    "    mealDatesList.append(l)\n",
    "\n",
    "mealDataMatrix = []\n",
    "for mealDateTime in mealDatesList:\n",
    "    idx = cgmDf[cgmDf['Date_Time'] == mealDateTime[0]]['Sensor Glucose (mg/dL)'].index[0]\n",
    "    l = list(cgmDf['Sensor Glucose (mg/dL)'].iloc[cgmDf.shape[0]-1-idx-6:cgmDf.shape[0]-1-idx+24].values)\n",
    "    l.append(mealDateTime[1])\n",
    "    mealDataMatrix.append(l)\n",
    "\n",
    "mealDf = pd.DataFrame(mealDataMatrix).dropna()\n",
    "mealDf = mealDf.reset_index(drop=True)\n",
    "\n",
    "#Extract cgm velocity\n",
    "def extract_cgm_velocity(df, result_df):\n",
    "  velocityDF = pd.DataFrame()\n",
    "  for i in range(0,df.shape[1]-5):\n",
    "      velocityDF['Vel_'+str(i)] = (df.iloc[:,i+5]-df.iloc[:,i])\n",
    "  result_df['Window_Velocity_Max']=velocityDF.max(axis = 1, skipna=True)\n",
    "\n",
    "#Extract cgm trend\n",
    "def extract_cgm_trend(df, result_df):\n",
    "    lunch = [[]]\n",
    "    means = []\n",
    "    for i in range(1, len(df)):\n",
    "        lunch.append(df.iloc[i])\n",
    "    for i in range(0, len(lunch)):\n",
    "        means.append(df.iloc[i].mean())\n",
    "    countmaster = []\n",
    "    for i in range(0, len(lunch)):\n",
    "        count = 0\n",
    "        for j in df.iloc[i]:\n",
    "            if j < means[i]:    \n",
    "                count += 1\n",
    "        countmaster.append(count)\n",
    "    percentage=[]\n",
    "    for i in countmaster:\n",
    "        percentage.append((i / len(df.iloc[0])) * 100)\n",
    "    result_df['cgmTrend'] = np.asarray(percentage)\n",
    "\n",
    "#Extract Accelaration\n",
    "def extract_acceleration(df, result_df):\n",
    "    d=[]\n",
    "    q=[]\n",
    "    f=[]\n",
    "    acc = [[],[],[],[]]\n",
    "    for j in range(0, df.shape[0]):\n",
    "        b = df.iloc[j]\n",
    "        d = []\n",
    "        for i in range(len(b)):\n",
    "            if(np.isnan(b[i])):\n",
    "                continue\n",
    "            else:\n",
    "                d.append(b[i])\n",
    "\n",
    "        if(len(d) >= 1):\n",
    "            solar_elevation_angle_1stdev = np.gradient(d)\n",
    "            solar_elevation_angle_2nddev = np.gradient(solar_elevation_angle_1stdev)\n",
    "\n",
    "            q = solar_elevation_angle_2nddev\n",
    "            arr = q[5:10]\n",
    "            acc[0].append(np.mean(arr))\n",
    "            arr = q[10:15]\n",
    "            acc[1].append(np.mean(arr))\n",
    "            arr = q[15:20]\n",
    "            acc[2].append(np.mean(arr))\n",
    "            arr = q[20:25]\n",
    "            acc[3].append(np.mean(arr))\n",
    "\n",
    "        else:\n",
    "            for i in range(4):\n",
    "              acc[i].append(0)\n",
    "    for i in range(4):\n",
    "      result_df['acc'+str(i+1)] = acc[i]\n",
    "\n",
    "#Extract entropy\n",
    "def get_entropy(series):\n",
    "    series_counts = series.value_counts()\n",
    "    entropy = scipy.stats.entropy(series_counts)  \n",
    "    return entropy\n",
    "\n",
    "def extract_entropy(df, result_df):\n",
    "    result_df['Entropy'] = df.apply(lambda row: get_entropy(row), axis=1)\n",
    "\n",
    "#Extract Windowed mean\n",
    "def extract_windowed_mean(df, result_df):\n",
    "  if(df.shape[1] > 24):\n",
    "    for i in range(6,df.shape[1],6):\n",
    "      result_df['Mean_'+str(i-6)] = df.iloc[:,i:i+6].mean(axis = 1)\n",
    "  else:\n",
    "    for i in range(0,df.shape[1],6):\n",
    "      result_df['Mean_'+str(i)] = df.iloc[:,i:i+6].mean(axis = 1)\n",
    "\n",
    "# FFT- Finding top 8 values for each row\n",
    "from numpy.fft import fft\n",
    "def get_fft(row):\n",
    "    cgmFFTValues = np.abs(fft(row))\n",
    "    cgmFFTValues.sort()\n",
    "    return np.flip(cgmFFTValues)[0:8]\n",
    "\n",
    "def extract_fft(df, result_df):\n",
    "  FFT = pd.DataFrame()\n",
    "  FFT['FFT_Top2'] = df.apply(lambda row: get_fft(row), axis=1)\n",
    "  FFT_updated = pd.DataFrame(FFT.FFT_Top2.tolist(), columns=['FFT_1', 'FFT_2', 'FFT_3', 'FFT_4', 'FFT_5', 'FFT_6', 'FFT_7', 'FFT_8'])\n",
    "  FFT_updated.head()\n",
    "  for i in range(8):\n",
    "    result_df['FFT_'+str(i+1)] = FFT_updated['FFT_'+str(i+1)]\n",
    "    \n",
    "#get MinMaxDiff for each row\n",
    "def get_minMaxDiff(series):\n",
    "    return series.max() - series.min()\n",
    "    \n",
    "#Extract MinMaxDiff\n",
    "def extract_minMaxDiff(df, result_df):\n",
    "    result_df['MinMaxDifference']= df.apply(lambda row: get_minMaxDiff(row), axis=1)   \n",
    "\n",
    "#1. Feature extraction\n",
    "meal_features = pd.DataFrame()\n",
    "result_dffft = pd.DataFrame()\n",
    "\n",
    "def extract_features(data, result_df):\n",
    "    extract_minMaxDiff(data, result_df)\n",
    "    extract_cgm_velocity(data, result_df)\n",
    "    extract_windowed_mean(data, result_df)\n",
    "    extract_cgm_trend(data, result_df)\n",
    "    extract_acceleration(data, result_df)\n",
    "    extract_entropy(data, result_df)\n",
    "    extract_fft(data, result_df)    \n",
    "\n",
    "extract_features(mealDf.iloc[:,:-1], meal_features)\n",
    "meal_features\n",
    "\n",
    "# # PCA\n",
    "pca = PCA(n_components=10)\n",
    "#Fit meal features\n",
    "principalComponents = pca.fit(meal_features)\n",
    "#Transform meal features\n",
    "PCA_mealdata = pca.fit_transform(meal_features)\n",
    "PCA_mealdata\n",
    "\n",
    "def CalcEucDist(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "#KMeans clustering\n",
    "kmeans = KMeans(n_clusters=nBins, random_state=0).fit(PCA_mealdata)\n",
    "\n",
    "SSEKMeans = kmeans.inertia_\n",
    "\n",
    "\n",
    "def calcEntropyPurity(labels):\n",
    "    clusterBinMatrix = [[0 for i in range(nBins)] for i in range(nBins)]\n",
    "    for i in range(labels.shape[0]):\n",
    "        clusterBinMatrix[labels[i]][int(mealDf.iloc[i][30])] += 1\n",
    "    WholeEntropy = 0\n",
    "    Entropy = [0 for i in range(6)]\n",
    "    Purity = 0\n",
    "    totalPoints = sum(sum(clusterBinMatrix,[]))\n",
    "    for i in range(len(clusterBinMatrix)):\n",
    "        Purity += max(clusterBinMatrix[i])/totalPoints\n",
    "        for j in range(len(clusterBinMatrix[i])):\n",
    "            P = clusterBinMatrix[i][j]/sum(clusterBinMatrix[i])\n",
    "            if(P != 0):\n",
    "                Entropy[i] += (-P) * log2(P) * (sum(clusterBinMatrix[i])/totalPoints)\n",
    "    WholeEntropy = sum(Entropy)\n",
    "    return WholeEntropy,Purity     \n",
    "\n",
    "KmeansEntropy, KmeansPurity = calcEntropyPurity(kmeans.labels_)\n",
    "\n",
    "#DBSCAN Clustering\n",
    "db_default = DBSCAN(eps = 224, min_samples = 6).fit(PCA_mealdata) \n",
    "labels = db_default.labels_ \n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == -1:\n",
    "        dist = float('inf')\n",
    "        l = -1\n",
    "        for j in range(len(labels)):\n",
    "            if db_default.labels_[j] != -1:\n",
    "                eucDist = CalcEucDist(PCA_mealdata[i], PCA_mealdata[j])\n",
    "                if eucDist < dist:\n",
    "                    dist = eucDist\n",
    "                    l = db_default.labels_[j]\n",
    "        labels[i] = l\n",
    "db_default.labels_ = np.array(labels)\n",
    "\n",
    "dbScanSSE = 0\n",
    "for i in range(nBins):\n",
    "    cluster = PCA_mealdata[db_default.labels_ == i]\n",
    "    clusterMean = cluster.mean(axis = 0)\n",
    "    dbScanSSE += ((cluster - clusterMean) ** 2).sum()\n",
    "\n",
    "dbScanEntropy,dbScanPurity = calcEntropyPurity(db_default.labels_)\n",
    "\n",
    "\n",
    "result = {\n",
    "    'SSE for Kmeans': [SSEKMeans],\n",
    "    'SSE for DBSCAN': [dbScanSSE],\n",
    "    'Entropy for Kmeans': [KmeansEntropy],\n",
    "    'Entropy for DBSCAN': [dbScanEntropy],\n",
    "    'Purity for Kmeans': [KmeansPurity],\n",
    "    'Purity for DBSCAN': [dbScanPurity]\n",
    "}\n",
    "print(KmeansEntropy)\n",
    "resultDf = pd.DataFrame(result,index = [1])\n",
    "resultDf\n",
    "print(\"=====================Done===========================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

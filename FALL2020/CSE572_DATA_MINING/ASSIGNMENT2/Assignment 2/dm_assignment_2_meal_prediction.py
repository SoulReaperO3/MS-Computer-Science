# -*- coding: utf-8 -*-
"""DM Assignment 2 Meal Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XY2Q4MguQ12OAqzrQ94Ll7ohme1Rj79C
"""



import pandas as pd
import pandas
import numpy as np
import matplotlib.pyplot as plt
import pywt
from sklearn.model_selection import train_test_split
import scipy
import scipy.fftpack
from sklearn.decomposition import PCA
from sklearn import tree
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix
import pickle


#load Insulin and CGM Data
insulinDf = pandas.read_csv('InsulinData.csv', parse_dates=[['Date','Time']],low_memory=False).iloc[::-1]
cgmDf = pandas.read_csv('CGMData.csv', parse_dates=[['Date','Time']],low_memory=False).iloc[::-1]

insulinDf2 = pandas.read_csv('InsulinAndMealIntake670GPatient3.csv', parse_dates=[['Date','Time']],low_memory=False).iloc[::-1]
cgmDf2 = pandas.read_csv('CGMData670GPatient3.csv', parse_dates=[['Date','Time']],low_memory=False).iloc[::-1]

cgmDf

#filter NaNs and Zeros
insulinDFColY = insulinDf[insulinDf['BWZ Carb Input (grams)'].notnull() & insulinDf['BWZ Carb Input (grams)'] != 0]
insulinMealDates = pandas.DataFrame(insulinDFColY['Date_Time'])
insulinMealDates

insulinDFColY2 = insulinDf2[insulinDf2['BWZ Carb Input (grams)'].notnull() & insulinDf2['BWZ Carb Input (grams)'] != 0]
insulinMealDates2 = pandas.DataFrame(insulinDFColY2['Date_Time'])
insulinMealDates2

#mealStartDates from Insulin CSV
insulinMealDates['Diff'] = insulinMealDates.iloc[:,0].diff(-1).dt.total_seconds().div(3600)
insulinMealDates = insulinMealDates.loc[insulinMealDates['Diff'] <= -2]
insulinNoMealDates = insulinMealDates.loc[insulinMealDates['Diff'] <= -4]
insulinMealDates.drop(insulinMealDates.head(1).index,inplace=True)
insulinMealDates.drop(insulinMealDates.tail(2).index,inplace=True)
insulinNoMealDates.drop(insulinNoMealDates.head(1).index,inplace=True)
insulinNoMealDates.drop(insulinNoMealDates.tail(2).index,inplace=True)
insulinNoMealDates

insulinMealDates2['Diff'] = insulinMealDates2.iloc[:,0].diff(-1).dt.total_seconds().div(3600)
insulinMealDates2 = insulinMealDates2.loc[insulinMealDates2['Diff'] <= -2]
insulinNoMealDates2 = insulinMealDates2.loc[insulinMealDates2['Diff'] <= -4]
insulinMealDates2.drop(insulinMealDates2.head(1).index,inplace=True)
insulinMealDates2.drop(insulinMealDates2.tail(2).index,inplace=True)
insulinNoMealDates2.drop(insulinNoMealDates2.head(1).index,inplace=True)
insulinNoMealDates2.drop(insulinNoMealDates2.tail(2).index,inplace=True)
insulinNoMealDates2

mealDatesList = []
for ind in insulinMealDates.index: 
#     print("InsulinMealData : " + str(insulinMealDates['Date_Time'][ind]))
    mealDatesList.append((cgmDf.loc[cgmDf['Date_Time'] >= insulinMealDates['Date_Time'][ind]])['Date_Time'].iloc[0])
mealDatesList

noMealDatesList = []
for ind in insulinNoMealDates.index: 
#     print("InsulinMealData : " + str(insulinMealDates['Date_Time'][ind]))
    noMealDatesList.append((cgmDf.loc[cgmDf['Date_Time'] >= insulinNoMealDates['Date_Time'][ind]])['Date_Time'].iloc[0])
noMealDatesList


mealDatesList2 = []
for ind in insulinMealDates2.index: 
#     print("InsulinMealData : " + str(insulinMealDates['Date_Time'][ind]))
    mealDatesList2.append((cgmDf2.loc[cgmDf2['Date_Time'] >= insulinMealDates2['Date_Time'][ind]])['Date_Time'].iloc[0])
mealDatesList2

noMealDatesList2 = []
for ind in insulinNoMealDates2.index: 
#     print("InsulinMealData : " + str(insulinMealDates['Date_Time'][ind]))
    noMealDatesList2.append((cgmDf2.loc[cgmDf2['Date_Time'] >= insulinNoMealDates2['Date_Time'][ind]])['Date_Time'].iloc[0])
noMealDatesList2

mealDataMatrix = []
for mealDateTime in mealDatesList:
    idx = cgmDf[cgmDf['Date_Time'] == mealDateTime]['Sensor Glucose (mg/dL)'].index[0]
    mealDataMatrix.append(list(cgmDf['Sensor Glucose (mg/dL)'].iloc[cgmDf.shape[0]-1-idx-6:cgmDf.shape[0]-1-idx+24].values))
mealDataMatrix

noMealDataMatrix = []
for noMealDateTime in noMealDatesList:
    idx = cgmDf[cgmDf['Date_Time'] == noMealDateTime]['Sensor Glucose (mg/dL)'].index[0]
    noMealDataMatrix.append(list(cgmDf['Sensor Glucose (mg/dL)'].iloc[cgmDf.shape[0]-1-idx+24:cgmDf.shape[0]-1-idx+48].values))

# idx = cgmDf['Date_Time'].loc[lambda x: x=='2017-07-28 21:39:14'].index
# idx
# (cgmDf.iloc[idx[0] - 24 : idx[0] + 6])['Sensor Glucose (mg/dL)']

mealDf = pandas.DataFrame(mealDataMatrix).dropna()
mealDfAvg = mealDf.mean(axis=0)
mealDfAvg


noMealDf = pandas.DataFrame(noMealDataMatrix).dropna()
print(noMealDf.shape[0])
noMealDfAvg = noMealDf.mean(axis=0)
noMealDfAvg



mealDataMatrix2 = []
for mealDateTime2 in mealDatesList2:
    idx = cgmDf2[cgmDf2['Date_Time'] == mealDateTime2]['Sensor Glucose (mg/dL)'].index[0]
    mealDataMatrix2.append(list(cgmDf2['Sensor Glucose (mg/dL)'].iloc[cgmDf2.shape[0]-1-idx-6:cgmDf2.shape[0]-1-idx+24].values))
mealDataMatrix2

noMealDataMatrix2 = []
for noMealDateTime2 in noMealDatesList2:
    idx = cgmDf2[cgmDf2['Date_Time'] == noMealDateTime2]['Sensor Glucose (mg/dL)'].index[0]
    noMealDataMatrix2.append(list(cgmDf2['Sensor Glucose (mg/dL)'].iloc[cgmDf2.shape[0]-1-idx+24:cgmDf2.shape[0]-1-idx+48].values))

# idx = cgmDf['Date_Time'].loc[lambda x: x=='2017-07-28 21:39:14'].index
# idx
# (cgmDf.iloc[idx[0] - 24 : idx[0] + 6])['Sensor Glucose (mg/dL)']

mealDf2 = pandas.DataFrame(mealDataMatrix2).dropna()
mealDfAvg2 = mealDf2.mean(axis=0)
mealDfAvg2

noMealDf2 = pandas.DataFrame(noMealDataMatrix2).dropna()
print(noMealDf2.shape[0])
noMealDfAvg2 = noMealDf2.mean(axis=0)
noMealDfAvg2

plt.plot(mealDfAvg)
plt.plot(noMealDfAvg,color='orange')
plt.show()

plt.plot(mealDfAvg2)
plt.plot(noMealDfAvg2,color='orange')
plt.show()

meal = pandas.concat([mealDf, mealDf2], ignore_index=True, sort = False)
mealDataMatrix = meal.values.tolist()
no_meal = pandas.concat([noMealDf, noMealDf2], ignore_index=True, sort = False)
noMealDataMatrix = no_meal.values.tolist()
print(meal)
print(no_meal)

mealDfAvg = meal.mean(axis=0)
mealDfAvg


noMealDfAvg = no_meal.mean(axis=0)
noMealDfAvg

plt.plot(mealDfAvg)
plt.plot(noMealDfAvg,color='orange')
plt.show()

def extract_cgm_velocity(df, result_df):
  velocityDF = pd.DataFrame()
  for i in range(0,df.shape[1]-5):
      velocityDF['Vel_'+str(i)] = (df.iloc[:,i+5]-df.iloc[:,i])
  result_df['Window_Velocity_Max']=velocityDF.max(axis = 1, skipna=True)

def extract_cgm_trend(df, result_df):
    lunch = [[]]
    means = []
    for i in range(1, len(df)):
        lunch.append(df.iloc[i])
    for i in range(0, len(lunch)):
        means.append(df.iloc[i].mean())
    countmaster = []
    for i in range(0, len(lunch)):
        count = 0
        for j in df.iloc[i]:
            if j < means[i]:    
                count += 1
        countmaster.append(count)
    percentage=[]
    for i in countmaster:
        percentage.append((i / len(df.iloc[0])) * 100)
    result_df['cgmTrend'] = np.asarray(percentage)

#Extract Accelaration
def extract_acceleration(df, result_df):
    d=[]
    q=[]
    f=[]
    acc = [[],[],[],[]]
    for j in range(0, df.shape[0]):
        b = df.iloc[j]
        d = []
        for i in range(len(b)):
            if(np.isnan(b[i])):
                continue
            else:
                d.append(b[i])

        if(len(d) >= 1):
            solar_elevation_angle_1stdev = np.gradient(d)
            solar_elevation_angle_2nddev = np.gradient(solar_elevation_angle_1stdev)

            q = solar_elevation_angle_2nddev
            arr = q[5:10]
            acc[0].append(np.mean(arr))
            arr = q[10:15]
            acc[1].append(np.mean(arr))
            arr = q[15:20]
            acc[2].append(np.mean(arr))
            arr = q[20:25]
            acc[3].append(np.mean(arr))

        else:
            for i in range(4):
              acc[i].append(0)
    for i in range(4):
      result_df['acc'+str(i+1)] = acc[i]

#Extract entropy
def get_entropy(series):
    series_counts = series.value_counts()
    entropy = scipy.stats.entropy(series_counts)  
    return entropy

def extract_entropy(df, result_df):
    result_df['Entropy'] = df.apply(lambda row: get_entropy(row), axis=1)

#Extract Windowed mean
def extract_windowed_mean(df, result_df):
  if(df.shape[1] > 24):
    for i in range(6,df.shape[1],6):
      result_df['Mean_'+str(i-6)] = df.iloc[:,i:i+6].mean(axis = 1)
  else:
    for i in range(0,df.shape[1],6):
      result_df['Mean_'+str(i)] = df.iloc[:,i:i+6].mean(axis = 1)

# FFT- Finding top 8 values for each row
from numpy.fft import fft
def get_fft(row):
    cgmFFTValues = np.abs(fft(row))
    cgmFFTValues.sort()
    return np.flip(cgmFFTValues)[0:8]

def extract_fft(df, result_df):
  FFT = pd.DataFrame()
  FFT['FFT_Top2'] = df.apply(lambda row: get_fft(row), axis=1)
  FFT_updated = pd.DataFrame(FFT.FFT_Top2.tolist(), columns=['FFT_1', 'FFT_2', 'FFT_3', 'FFT_4', 'FFT_5', 'FFT_6', 'FFT_7', 'FFT_8'])
  FFT_updated.head()
  for i in range(8):
    result_df['FFT_'+str(i+1)] = FFT_updated['FFT_'+str(i+1)]

#1. Feature extraction
meal_features = pd.DataFrame()
no_meal_features = pd.DataFrame()

def extract_features(data, result_df) : 
    extract_cgm_velocity(data, result_df)
    extract_windowed_mean(data, result_df)
    extract_cgm_trend(data, result_df)
    extract_fft(data, result_df)
    extract_acceleration(data, result_df)
    extract_entropy(data, result_df)

extract_features(meal, meal_features)
#print(meal_features)
extract_features(no_meal, no_meal_features)
#print(no_meal_features)




# # PCA
pca = PCA(n_components=10)
#Fit meal features
principalComponents = pca.fit(meal_features)
#Transform meal features
PCA_mealdata = pca.fit_transform(meal_features)

#Fit no-meal features
principalComponents = pca.fit(no_meal_features)
#Tranform no-meal features
PCA_nomealdata = pca.fit_transform(no_meal_features)

#Create feature matrix
Training_data = np.concatenate((PCA_mealdata, PCA_nomealdata), axis=0)

Training_labels = []
no_of_mealrows = meal.shape[0]
no_of_nomealrows = no_meal.shape[0]
for i in range(no_of_mealrows) :
    Training_labels.append(1)
for i in range(no_of_nomealrows) :
    Training_labels.append(0)

#3. Training classifiers
X = pd.DataFrame(Training_data)
y = pd.DataFrame(Training_labels)
Z = pd.concat([X, y], axis=1, sort=False)

#Randomize data
Total_Data = Z.reindex(np.random.permutation(Z.index))

#K fold cross validation
kf = RepeatedKFold(n_splits=5, n_repeats=5)

#Decision Tree
for train_index, test_index in kf.split(Total_Data):
    trainData = Total_Data.iloc[train_index, 0:10]
    trainLabel = Total_Data.iloc[train_index, 10]
    testData = Total_Data.iloc[test_index, 0:10]
    testLabel = Total_Data.iloc[test_index, 10]

    classifier = tree.DecisionTreeClassifier()
    classifier.fit(trainData, trainLabel)
    predictedLabel = classifier.predict(testData)
    
    acc = int(accuracy_score(testLabel, predictedLabel)*100)
    
    print(classification_report(testLabel, predictedLabel))
    print(confusion_matrix(testLabel, predictedLabel))

    filename = str(acc)+"_decision_tree.pkl"
    pickle.dump(classifier, open(filename, 'wb'))
# -*- coding: utf-8 -*-
"""testNx24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/123gSJekRUpMMXGfyrEhK3fFUte16luTq
"""

import pandas as pd
import pandas
import numpy as np
import matplotlib.pyplot as plt
import pywt
from sklearn.model_selection import train_test_split
import scipy
import scipy.fftpack

testSet = pd.read_csv("/content/drive/My Drive/noMeal.csv", error_bad_lines=False)
testSet

def extract_cgm_velocity(df, result_df):
  velocityDF = pd.DataFrame()
  for i in range(0,df.shape[1]-5):
      velocityDF['Vel_'+str(i)] = (df.iloc[:,i+5]-df.iloc[:,i])
  result_df['Window_Velocity_Max']=velocityDF.max(axis = 1, skipna=True)

def extract_cgm_trend(df, result_df):
    lunch = [[]]
    means = []
    for i in range(1, len(df)):
        lunch.append(df.iloc[i])
    for i in range(0, len(lunch)):
        means.append(df.iloc[i].mean())
    countmaster = []
    for i in range(0, len(lunch)):
        count = 0
        for j in df.iloc[i]:
            if j < means[i]:    
                count += 1
        countmaster.append(count)
    percentage=[]
    for i in countmaster:
        percentage.append((i / len(df.iloc[0])) * 100)
    result_df['cgmTrend'] = np.asarray(percentage)

#Extract Accelaration
def extract_acceleration(df, result_df):
    d=[]
    q=[]
    f=[]
    acc = [[],[],[],[]]
    for j in range(0, df.shape[0]):
        b = df.iloc[j]
        d = []
        for i in range(len(b)):
            if(np.isnan(b[i])):
                continue
            else:
                d.append(b[i])

        if(len(d) >= 1):
            solar_elevation_angle_1stdev = np.gradient(d)
            solar_elevation_angle_2nddev = np.gradient(solar_elevation_angle_1stdev)

            q = solar_elevation_angle_2nddev
            arr = q[5:10]
            acc[0].append(np.mean(arr))
            arr = q[10:15]
            acc[1].append(np.mean(arr))
            arr = q[15:20]
            acc[2].append(np.mean(arr))
            arr = q[20:25]
            acc[3].append(np.mean(arr))

        else:
            for i in range(4):
              acc[i].append(0)
    for i in range(4):
      result_df['acc'+str(i+1)] = acc[i]

#Extract entropy
def get_entropy(series):
    series_counts = series.value_counts()
    entropy = scipy.stats.entropy(series_counts)  
    return entropy

def extract_entropy(df, result_df):
    result_df['Entropy'] = df.apply(lambda row: get_entropy(row), axis=1)

#Extract PolyFit
def extract_polyfit(df, result_df):
   
    colid = []
    no_of_rows = df.shape[0]
    no_of_cols = df.shape[1]

    result = df.T
    no_of_coefficients = 6
    cols = []
    for i in range(0, no_of_rows) :
        cols.append(str(i))
    result.columns = cols
    
    for i in range(0, no_of_cols) :
        colid.append(i + 1)
    x = np.array(colid)
    fftmatrix = []
    
    for i in range(0, no_of_rows) :
        y = np.array(result[str(i)])
        polyres = np.polyfit(x, y, no_of_coefficients-1)  
        fftmatrix.append(polyres.tolist())
    fftmatrix = np.array(fftmatrix)   
  
    for i in range(no_of_coefficients) :
        result_df['Coefficient'+str(i)] = fftmatrix[:, i]
    #return result_df
    result_df.head()

#Extract Windowed mean
def extract_windowed_mean(df, result_df):
  if(df.shape[1] > 24):
    for i in range(6,df.shape[1],6):
      result_df['Mean_'+str(i-6)] = df.iloc[:,i:i+6].mean(axis = 1)
  else:
    for i in range(0,df.shape[1],6):
      result_df['Mean_'+str(i)] = df.iloc[:,i:i+6].mean(axis = 1)

# FFT- Finding top 8 values for each row
import pywt
from numpy.fft import fft
def get_fft(row):
    cgmFFTValues = np.abs(fft(row))
    cgmFFTValues.sort()
    return np.flip(cgmFFTValues)[0:8]

def extract_fft(df, result_df):
  FFT = pd.DataFrame()
  FFT['FFT_Top2'] = df.apply(lambda row: get_fft(row), axis=1)
  FFT_updated = pd.DataFrame(FFT.FFT_Top2.tolist(), columns=['FFT_1', 'FFT_2', 'FFT_3', 'FFT_4', 'FFT_5', 'FFT_6', 'FFT_7', 'FFT_8'])
  FFT_updated.head()
  for i in range(8):
    result_df['FFT_'+str(i+1)] = FFT_updated['FFT_'+str(i+1)]

#1. Feature extraction
test_features = pd.DataFrame()

def extract_features(data, result_df) : 
    extract_cgm_velocity(data, result_df)
    extract_windowed_mean(data, result_df)
    extract_cgm_trend(data, result_df)
    extract_fft(data, result_df)
    extract_acceleration(data, result_df)
    extract_entropy(data, result_df)
    # extract_polyfit(data, result_df)

extract_features(testSet, test_features)


test_features
#

from sklearn.decomposition import PCA

# # PCA
pca = PCA(n_components=10)
#Fit meal features
principalComponents = pca.fit(test_features)
#Transform meal features
testData = pca.fit_transform(test_features)
testData

import pickle
clf = pickle.load(open('/content/drive/My Drive/89_decision_tree.pkl', 'rb'))
y_pred = clf.predict(testData)
new_y_pred = []
for i in y_pred:
    if(i > 0):
        new_y_pred.append(1)
    else:
        new_y_pred.append(0)
        
result = pd.DataFrame(new_y_pred)
result.to_csv('Result.csv', index=False)

print(new_y_pred)
count = 0
for i in new_y_pred:
  if(i == 0):
    count += 1

print("Correct prob: " + str(count/len(new_y_pred)))

res = pd.read_csv("/content/Result.csv", error_bad_lines=False)
res.shape